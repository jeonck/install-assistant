{
    "title": "Fluentd on Kubernetes DaemonSet Installation",
    "description": "A step-by-step guide to installing Fluentd as a DaemonSet on Kubernetes to collect application logs, including RBAC, ConfigMap, and DaemonSet configurations.",
    "steps": [
        {
            "text": "Create `fluentd-rbac.yaml`",
            "description": "This file defines the `ServiceAccount`, `ClusterRole`, and `ClusterRoleBinding` necessary for Fluentd to operate within your Kubernetes cluster.",
            "code": "apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: fluentd\n  namespace: kube-system\n  labels:\n    app: fluentd\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: fluentd\n  labels:\n    app: fluentd\nrules:\n- apiGroups: [\"\"]\n  resources:\n  - pods\n  - namespaces\n  verbs:\n  - get\n  - list\n  - watch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: fluentd\n  labels:\n    app: fluentd\nroleRef:\n  kind: ClusterRole\n  name: fluentd\n  apiGroup: rbac.authorization.k8s.io\nsubjects:\n- kind: ServiceAccount\n  name: fluentd\n  namespace: kube-system"
        },
        {
            "text": "Create `fluentd-configmap.yaml`",
            "description": "This `ConfigMap` holds the Fluentd configuration. This example is set up to collect logs from `/var/log/containers/*.log` (for container logs), `/run/log/journal` (for systemd journal logs), and various Kubernetes component logs, then output them to an Elasticsearch instance. You might need to adjust the `FLUENT_ELASTICSEARCH_HOST` and `FLUENT_ELASTICSEARCH_PORT` environment variables in the DaemonSet if your Elasticsearch is not at `elasticsearch.default.svc.cluster.local:9200`.",
            "code": "apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: fluentd-config\n  namespace: kube-system\n  labels:\n    app: fluentd\ndata:\n  fluent.conf: |\n    <match kubernetes.**>\n      @id elasticsearch\n      @type elasticsearch\n      @log_level info\n      host \"#{ENV[\\'FLUENT_ELASTICSEARCH_HOST\\']}\"\n      port \"#{ENV[\\'FLUENT_ELASTICSEARCH_PORT\\']}\"\n      scheme \"#{ENV[\\'FLUENT_ELASTICSEARCH_SCHEME\\']}\"\n      logstash_format true\n      logstash_prefix fluentd\n      logstash_dateformat %Y%m%d\n      include_tag_key true\n      type_name doc\n      tag_key @log_name\n      flush_interval 5s\n      <buffer>\n        @type file\n        path /var/log/fluentd-buffer-elasticsearch.buffer\n        flush_interval 5s\n        chunk_limit_size 2M\n        queue_limit_length 8\n        retry_max_interval 30\n        retry_forever true\n      </buffer>\n    </match>\n\n    <source>\n      @id tail_containers\n      @type tail\n      @log_level info\n      path /var/log/containers/*.log\n      pos_file /var/log/fluentd-containers.log.pos\n      tag kubernetes.* \n      read_from_head true\n      <parse>\n        @type json\n        time_key time\n        time_format %Y-%m-%dT%H:%M:%S.%NZ\n      </parse>\n    </source>\n\n    <source>\n      @id tail_journald\n      @type systemd\n      @log_level info\n      path /run/log/journal\n      tag journald.*\n      read_from_head true\n      <entry>\n        field_map {\n          \"MESSAGE\": \"message\",\n          \"_HOSTNAME\": \"hostname\"\n        }\n      </entry>\n      <parse>\n        @type json\n        time_key _SOURCE_REALTIME_TIMESTAMP\n        time_format %s%L\n      </nparse>\n    </source>\n\n    <source>\n      @id tail_kubelet\n      @type tail\n      @log_level info\n      path /var/log/kubelet.log\n      pos_file /var/log/fluentd-kubelet.log.pos\n      tag kubernetes.kubelet\n      read_from_head true\n      <parse>\n        @type regexp\n        expression /^(?<time>[^ ]* [^ ]*) (?<level>[^ ]*) (?<source>[^:]*):(?<message>.*)$/\n        time_format %Y-%m-%d %H:%M:%S.%N\n        keep_time_key true\n      </parse>\n    </source>\n\n    <source>\n      @id tail_apiserver\n      @type tail\n      @log_level info\n      path /var/log/kube-apiserver.log\n      pos_file /var/log/fluentd-kube-apiserver.log.pos\n      tag kubernetes.apiserver\n      read_from_head true\n      <parse>\n        @type regexp\n        expression /^(?<time>[^ ]* [^ ]*) (?<level>[^ ]*) (?<source>[^:]*):(?<message>.*)$/\n        time_format %Y-%m-%d %H:%M:%S.%N\n        keep_time_key true\n      </parse>\n    </source>\n\n    <source>\n      @id tail_controller_manager\n      @type tail\n      @log_level info\n      path /var/log/kube-controller-manager.log\n      pos_file /var/log/fluentd-kube-controller-manager.log.pos\n      tag kubernetes.controller-manager\n      read_from_head true\n      <parse>\n        @type regexp\n        expression /^(?<time>[^ ]* [^ ]*) (?<level>[^ ]*) (?<source>[^:]*):(?<message>.*)$/\n        time_format %Y-%m-%d %H:%M:%S.%N\n        keep_time_key true\n      </parse>\n    </source>\n\n    <source>\n      @id tail_scheduler\n      @type tail\n      @log_level info\n      path /var/log/kube-scheduler.log\n      pos_file /var/log/fluentd-kube-scheduler.log.pos\n      tag kubernetes.scheduler\n      read_from_head true\n      <parse>\n        @type regexp\n        expression /^(?<time>[^ ]* [^ ]*) (?<level>[^ ]*) (?<source>[^:]*):(?<message>.*)$/\n        time_format %Y-%m-%d %H:%M:%S.%N\n        keep_time_key true\n      </parse>\n    </source>\n\n    <source>\n      @id tail_etcd\n      @type tail\n      @log_level info\n      path /var/log/etcd.log\n      pos_file /var/log/fluentd-etcd.log.pos\n      tag kubernetes.etcd\n      read_from_head true\n      <parse>\n        @type regexp\n        expression /^(?<time>[^ ]* [^ ]*) (?<level>[^ ]*) (?<source>[^:]*):(?<message>.*)$/\n        time_format %Y-%m-%d %H:%M:%S.%N\n        keep_time_key true\n      </parse>\n    </source>\n\n    <source>\n      @id tail_audit\n      @type tail\n      @log_level info\n      path /var/log/audit/audit.log\n      pos_file /var/log/fluentd-audit.log.pos\n      tag audit.*\n      read_from_head true\n      <parse>\n        @type regexp\n        expression /type=(?<type>[^ ]*) audit\\((?<time>[^:]*):(?<id>[^)]*)\\):(?<message>.*)$/\n        time_format %s.%L\n        keep_time_key true\n      </parse>\n    </source>\n\n    <filter kubernetes.**>\n      @id kubernetes_metadata\n      @type kubernetes_metadata\n      @log_level info\n      kubernetes_url \"#{ENV[\\'KUBERNETES_SERVICE_HOST\\']}\":\"#{ENV[\\'KUBERNETES_SERVICE_PORT\\']}\"\n      verify_ssl_peer false\n      ca_file /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n      skip_labels true\n      skip_container_metadata true\n      skip_master_url true\n      skip_namespace_metadata false\n    </filter>\n\n    <filter journald.**>\n      @id journald_parser\n      @type parser\n      key_name message\n      <parse>\n        @type multi_format\n        <pattern>\n          format json\n        </pattern>\n        <pattern>\n          format regexp\n          expression /^(?<severity>\\w)(?<time>\\d{2}\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{6}) (?<pid>\\d+)(?:\\[(?<thread>\\d+)\\])? (?<file>[^:]+):(?<line>\\d+)\\] (?<message>.*)/ \n        </pattern>\n        <pattern>\n          format none\n        </pattern>\n      </parse>\n    </filter>\n\n    <match **>\n      @type stdout\n    </match>"
        },
        {
            "text": "Create `fluentd-daemonset.yaml`",
            "description": "This `DaemonSet` ensures that a Fluentd pod runs on every node in your cluster. It mounts the necessary host paths for log collection and injects the Fluentd configuration.",
            "code": "apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: fluentd\n  namespace: kube-system\n  labels:\n    app: fluentd\nspec:\n  selector:\n    matchLabels:\n      app: fluentd\n  template:\n    metadata:\n      labels:\n        app: fluentd\n    spec:\n      serviceAccountName: fluentd\n      tolerations:\n      - key: node-role.kubernetes.io/master\n        effect: NoSchedule\n      containers:\n      - name: fluentd\n        image: fluent/fluentd-kubernetes-daemonset:v1.16.0-debian-elasticsearch7-1.0\n        env:\n          - name: FLUENT_ELASTICSEARCH_HOST\n            value: \"elasticsearch.default.svc.cluster.local\"\n          - name: FLUENT_ELASTICSEARCH_PORT\n            value: \"9200\"\n          - name: FLUENT_ELASTICSEARCH_SCHEME\n            value: \"http\"\n          - name: FLUENT_UID\n            value: \"0\"\n        resources:\n          limits:\n            memory: 200Mi\n          requests:\n            cpu: 100m\n            memory: 200Mi\n        volumeMounts:\n        - name: varlog\n          mountPath: /var/log\n        - name: varlibdockercontainers\n          mountPath: /var/lib/docker/containers\n          readOnly: true\n        - name: fluentd-config\n          mountPath: /fluentd/etc\n        - name: runlog\n          mountPath: /run/log\n      terminationGracePeriodSeconds: 30\n      volumes:\n      - name: varlog\n        hostPath:\n          path: /var/log\n      - name: varlibdockercontainers\n        hostPath:\n          path: /var/lib/docker/containers\n      - name: fluentd-config\n        configMap:\n          name: fluentd-config\n      - name: runlog\n        hostPath:\n          path: /run/log"
        },
        {
            "text": "Apply the configurations",
            "description": "Save each block of YAML content into separate files (e.g., `fluentd-rbac.yaml`, `fluentd-configmap.yaml`, `fluentd-daemonset.yaml`). Then apply them to your Kubernetes cluster using `kubectl`. Remember to adjust the Elasticsearch host and port in `fluentd-daemonset.yaml` if your setup differs from the default.",
            "command": "kubectl apply -f fluentd-rbac.yaml\nkubectl apply -f fluentd-configmap.yaml\nkubectl apply -f fluentd-daemonset.yaml"
        }
    ]
}